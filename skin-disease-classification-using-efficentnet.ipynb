{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including TensorFlow, Keras, and EfficientNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Dataset\n",
    "Load the skin disease dataset and preprocess the images and labels for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Preprocess Dataset\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_path = 'path_to_skin_disease_dataset'\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation and preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Rescale pixel values to [0, 1]\n",
    "    validation_split=0.2,  # Split the data into training and validation sets\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.2,  # Randomly zoom into images\n",
    "    shear_range=0.2  # Randomly shear images\n",
    ")\n",
    "\n",
    "# Load and preprocess the training data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),  # Resize images to 224x224 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Use the training subset\n",
    ")\n",
    "\n",
    "# Load and preprocess the validation data\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),  # Resize images to 224x224 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Use the validation subset\n",
    ")\n",
    "\n",
    "# Display class indices\n",
    "class_indices = train_generator.class_indices\n",
    "print(\"Class indices:\", class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained EfficientNetV2 B0 Model\n",
    "Load the EfficientNetV2 B0 model pretrained on ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pretrained EfficientNetV2 B0 Model\n",
    "\n",
    "# Load the EfficientNetV2 B0 model pretrained on ImageNet\n",
    "base_model = EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create a new model on top of it\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(class_indices), activation='softmax')  # Number of classes in the dataset\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify Model for Skin Disease Classification\n",
    "Modify the pretrained model to adapt it for skin disease classification by adding custom layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify Model for Skin Disease Classification\n",
    "\n",
    "# Load the EfficientNetV2 B0 model pretrained on ImageNet\n",
    "base_model = EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create a new model on top of it\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(class_indices), activation='softmax')  # Number of classes in the dataset\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the Model\n",
    "Compile the modified model with appropriate loss function, optimizer, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "\n",
    "# Compile the modified model with appropriate loss function, optimizer, and metrics\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # Use Adam optimizer with a learning rate of 0.001\n",
    "    loss='categorical_crossentropy',  # Use categorical crossentropy as the loss function\n",
    "    metrics=['accuracy']  # Track accuracy as the metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "Train the model using the preprocessed dataset and validate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "\n",
    "# Define callbacks for early stopping and saving the best model\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train the model using the training data and validate using the validation data\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,  # Number of epochs to train the model\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Plot training and validation accuracy and loss\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model\n",
    "Evaluate the trained model on the test dataset and report the performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "\n",
    "# Load the test data\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),  # Resize images to 224x224 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',  # Use the validation subset as test data\n",
    "    shuffle=False  # Do not shuffle the test data\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "# Generate predictions on the test data\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Calculate and display the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions\n",
    "Use the trained model to make predictions on new skin disease images and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "\n",
    "# Load a sample image for prediction\n",
    "sample_image_path = 'path_to_sample_image.jpg'\n",
    "sample_image = tf.keras.preprocessing.image.load_img(sample_image_path, target_size=(224, 224))\n",
    "sample_image_array = tf.keras.preprocessing.image.img_to_array(sample_image)\n",
    "sample_image_array = np.expand_dims(sample_image_array, axis=0)  # Add batch dimension\n",
    "sample_image_array = sample_image_array / 255.0  # Rescale pixel values to [0, 1]\n",
    "\n",
    "# Make a prediction on the sample image\n",
    "predictions = model.predict(sample_image_array)\n",
    "predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "predicted_class_label = class_labels[predicted_class]\n",
    "\n",
    "# Display the sample image and the prediction result\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(sample_image)\n",
    "plt.title(f'Predicted: {predicted_class_label}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
